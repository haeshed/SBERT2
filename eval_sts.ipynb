{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(52000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your fine-tuned model and tokenizer\n",
    "local_model_path = \"final_model_dir\"\n",
    "# model_name = \"your-finetuned-model-name\"\n",
    "model = BertForSequenceClassification.from_pretrained(local_model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Check for available GPU or use CPU\n",
    "# Check for MPS and CUDA availability\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"MPS is available\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your STS dataset\n",
    "# Assuming dataset is a CSV with columns: sid, score, sentence1, sentence2\n",
    "df = pd.read_csv(\"data/heb_sts_test.csv\")\n",
    "\n",
    "# Prepare the data\n",
    "sentence_pairs = list(zip(df['sentence1'], df['sentence2']))\n",
    "true_scores = df['score'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict similarity scores\n",
    "# def predict_similarity_old(sentence_pairs):\n",
    "#     predicted_scores = []\n",
    "#     for sent1, sent2 in sentence_pairs:\n",
    "#         # Tokenize the input sentences\n",
    "#         inputs = tokenizer(sent1, sent2, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        \n",
    "#         # Get the model predictions\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "#             logits = outputs.logits\n",
    "\n",
    "#         # Convert logits to similarity scores (assuming regression on a continuous scale, e.g., 0-5)\n",
    "#         score = logits.item()\n",
    "#         predicted_scores.append(score)\n",
    "    \n",
    "#     return predicted_scores\n",
    "\n",
    "def predict_similarity(sentence_pairs):\n",
    "    predicted_scores = []\n",
    "    for sent1, sent2 in sentence_pairs:\n",
    "        # Tokenize the input sentences\n",
    "        inputs = tokenizer(sent1, sent2, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        \n",
    "        # Get the model predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits  # Shape: [batch_size, num_labels]\n",
    "\n",
    "        # For a regression task, we assume num_labels should be 1.\n",
    "        # Ensure the logits tensor is converted to a single scalar value.\n",
    "        print(logits)\n",
    "        score = logits.squeeze().item()  # Convert logits to scalar if logits has more than one element\n",
    "        predicted_scores.append(score)\n",
    "    \n",
    "    return predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dicta-il/dictabert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Processing Sentences: 100%|██████████| 1379/1379 [00:44<00:00, 30.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.6642353544257372\n",
      "Spearman correlation: 0.6584267627560283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Untuned model\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom model with a different loss function\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        \n",
    "        return {'loss': loss, 'logits': logits, 'hidden_states': outputs.last_hidden_state}\n",
    "\n",
    "# Function to encode sentences and get embeddings\n",
    "def get_sentence_embedding(model, tokenizer, sentence, device):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        hidden_states = outputs['hidden_states']\n",
    "        sentence_embedding = hidden_states.mean(dim=1).squeeze()\n",
    "\n",
    "    return sentence_embedding.cpu().numpy()\n",
    "\n",
    "# Load Hebrew STS dataset for evaluation\n",
    "sts_file_path = \"data/heb_sts_test.csv\"\n",
    "sts_data = pd.read_csv(sts_file_path)\n",
    "\n",
    "# Assuming model and tokenizer are already defined and loaded\n",
    "model_name = 'dicta-il/dictabert'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = CustomModel(model_name, num_labels=3)  # Assuming 3 labels for your classification task\n",
    "\n",
    "# Move model to CPU for inference\n",
    "model.to('mps')\n",
    "model.eval()\n",
    "\n",
    "# Evaluate the model using STS dataset\n",
    "predicted_scores = []\n",
    "actual_scores = sts_data['score'].tolist()\n",
    "\n",
    "for index, row in tqdm(sts_data.iterrows(), total=len(sts_data), desc=\"Processing Sentences\"):\n",
    "    sentence1 = row['sentence1']\n",
    "    sentence2 = row['sentence2']\n",
    "    \n",
    "    emb1 = get_sentence_embedding(model, tokenizer, sentence1, 'mps')\n",
    "    emb2 = get_sentence_embedding(model, tokenizer, sentence2, 'mps')\n",
    "    \n",
    "    # Calculate cosine similarity and scale to 0-5\n",
    "    similarity = 1 - cosine(emb1, emb2)\n",
    "    predicted_scores.append(similarity * 5)  # Scale cosine similarity to 0-5 range\n",
    "            \n",
    "# Compute Pearson and Spearman correlations\n",
    "pearson_correlation, _ = pearsonr(predicted_scores, actual_scores)\n",
    "spearman_correlation, _ = spearmanr(predicted_scores, actual_scores)\n",
    "\n",
    "print(f'Pearson correlation: {pearson_correlation}')\n",
    "print(f'Spearman correlation: {spearman_correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences: 100%|██████████| 1379/1379 [00:39<00:00, 35.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.5610494443044348\n",
      "Spearman correlation: 0.578294553036155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Finetuned model\n",
    "\n",
    "# Custom model with a different loss function\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        \n",
    "        return {'loss': loss, 'logits': logits, 'hidden_states': outputs.last_hidden_state}\n",
    "\n",
    "# Function to encode sentences and get embeddings\n",
    "def get_sentence_embedding(model, tokenizer, sentence, device):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        hidden_states = outputs['hidden_states']\n",
    "        sentence_embedding = hidden_states.mean(dim=1).squeeze()\n",
    "\n",
    "    return sentence_embedding.cpu().numpy()\n",
    "\n",
    "# Load Hebrew STS dataset for evaluation\n",
    "sts_file_path = \"data/heb_sts_test.csv\"\n",
    "sts_data = pd.read_csv(sts_file_path)\n",
    "\n",
    "# Assuming model and tokenizer are already defined and loaded\n",
    "# model_name = 'dicta-il/dictabert'\n",
    "\n",
    "local_model_path = \"final_model_dir\"\n",
    "model = BertForSequenceClassification.from_pretrained(local_model_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "model = CustomModel(local_model_path, num_labels=3)  # Assuming 3 labels for your classification task\n",
    "\n",
    "# Move model to CPU for inference\n",
    "model.to('mps')\n",
    "model.eval()\n",
    "\n",
    "# Evaluate the model using STS dataset\n",
    "predicted_scores = []\n",
    "actual_scores = sts_data['score'].tolist()\n",
    "\n",
    "for index, row in tqdm(sts_data.iterrows(), total=len(sts_data), desc=\"Processing Sentences\"):\n",
    "    sentence1 = row['sentence1']\n",
    "    sentence2 = row['sentence2']\n",
    "    \n",
    "    emb1 = get_sentence_embedding(model, tokenizer, sentence1, 'mps')\n",
    "    emb2 = get_sentence_embedding(model, tokenizer, sentence2, 'mps')\n",
    "    \n",
    "    # Calculate cosine similarity and scale to 0-5\n",
    "    similarity = 1 - cosine(emb1, emb2)\n",
    "    predicted_scores.append(similarity * 5)  # Scale cosine similarity to 0-5 range\n",
    "            \n",
    "# Compute Pearson and Spearman correlations\n",
    "pearson_correlation, _ = pearsonr(predicted_scores, actual_scores)\n",
    "spearman_correlation, _ = spearmanr(predicted_scores, actual_scores)\n",
    "\n",
    "print(f'Pearson correlation: {pearson_correlation}')\n",
    "print(f'Spearman correlation: {spearman_correlation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.5696, -1.1135, -1.2360]], device='mps:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 3 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Predict similarity scores for the dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predicted_scores \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_pairs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 33\u001b[0m, in \u001b[0;36mpredict_similarity\u001b[0;34m(sentence_pairs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# For a regression task, we assume num_labels should be 1.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Ensure the logits tensor is converted to a single scalar value.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(logits)\n\u001b[0;32m---> 33\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert logits to scalar if logits has more than one element\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     predicted_scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_scores\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 3 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# Predict similarity scores for the dataset\n",
    "predicted_scores = predict_similarity(sentence_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute evaluation metrics\n",
    "pearson_corr, _ = pearsonr(true_scores, predicted_scores)\n",
    "spearman_corr, _ = spearmanr(true_scores, predicted_scores)\n",
    "mse = mean_squared_error(true_scores, predicted_scores)\n",
    "mae = mean_absolute_error(true_scores, predicted_scores)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Pearson Correlation Coefficient: {pearson_corr:.4f}\")\n",
    "print(f\"Spearman Rank Correlation Coefficient: {spearman_corr:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between sentences: 0.8723\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = \"final_model_dir\"\n",
    "# model_name = 'bert-base-uncased'  # or your specific model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Check for GPU or MPS (Apple Silicon)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Example sentences\n",
    "# sentence1 = \"A woman is styling her hair.\"\n",
    "# sentence2 = \"A girl is brushing her hair.\"\n",
    "# sentence1 = \"אישה מעצבת את שיערה\"\n",
    "# sentence2 = \"ילדה מברישה את שיערה\"\n",
    "# 0033,3.6,קבוצת גברים משחקת כדורגל על ​​החוף.,קבוצת נערים משחקת כדורגל על ​​החוף.\n",
    "# 0045,5,אישה אחת מודדת קרסול של אישה אחרת.,אישה מודדת קרסול של אישה אחרת.\n",
    "sentence1 = \"גבר פורס עגבנייה\"\n",
    "sentence2 = \"גבר פורס לחמנייה\"\n",
    "\n",
    "# Function to compute sentence embeddings\n",
    "def get_sentence_embedding(sentence, model, tokenizer, device):\n",
    "    # Tokenize input sentence\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Extract hidden states from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        hidden_states = outputs.last_hidden_state  # Shape: [batch_size, sequence_length, hidden_size]\n",
    "\n",
    "    # Get the mean of the token embeddings to form a sentence embedding\n",
    "    # Optionally, you can use other methods like CLS token ([0, 0, :])\n",
    "    sentence_embedding = torch.mean(hidden_states, dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    return sentence_embedding\n",
    "\n",
    "# Get embeddings for both sentences\n",
    "embedding1 = get_sentence_embedding(sentence1, model, tokenizer, device)\n",
    "embedding2 = get_sentence_embedding(sentence2, model, tokenizer, device)\n",
    "\n",
    "# Compute cosine similarity between embeddings\n",
    "cosine_sim = 1 - cosine(embedding1, embedding2)\n",
    "print(f\"Cosine Similarity between sentences: {cosine_sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation: 0.5610\n",
      "Spearman Correlation: 0.5783\n",
      "Mean Squared Error: 5.2739\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"data/heb_sts_test.csv\")\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = \"final_model_dir\"\n",
    "# model_name = 'bert-base-uncased'  # or any other pre-trained model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Check for GPU or MPS (Apple Silicon)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to compute sentence embeddings\n",
    "def get_sentence_embedding(sentence, model, tokenizer, device):\n",
    "    # Tokenize input sentence\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Extract hidden states from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        hidden_states = outputs.last_hidden_state  # Shape: [batch_size, sequence_length, hidden_size]\n",
    "\n",
    "    # Get the mean of the token embeddings to form a sentence embedding\n",
    "    sentence_embedding = torch.mean(hidden_states, dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    return sentence_embedding\n",
    "\n",
    "# Function to compute predicted similarity scores for all sentence pairs in the dataset\n",
    "def predict_similarity(df):\n",
    "    predicted_scores = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        sent1 = row['sentence1']\n",
    "        sent2 = row['sentence2']\n",
    "        \n",
    "        # Get embeddings for both sentences\n",
    "        embedding1 = get_sentence_embedding(sent1, model, tokenizer, device)\n",
    "        embedding2 = get_sentence_embedding(sent2, model, tokenizer, device)\n",
    "\n",
    "        # Compute cosine similarity between embeddings\n",
    "        cosine_sim = 1 - cosine(embedding1, embedding2)\n",
    "        predicted_scores.append(cosine_sim)\n",
    "    \n",
    "    return predicted_scores\n",
    "\n",
    "# Get predicted similarity scores for the dataset\n",
    "predicted_scores = predict_similarity(df)\n",
    "\n",
    "# Evaluate the model performance using Pearson correlation, Spearman correlation, and Mean Squared Error\n",
    "actual_scores = df['score'].values\n",
    "\n",
    "pearson_corr, _ = pearsonr(actual_scores, predicted_scores)\n",
    "spearman_corr, _ = spearmanr(actual_scores, predicted_scores)\n",
    "mse = mean_squared_error(actual_scores, predicted_scores)\n",
    "\n",
    "print(f\"Pearson Correlation: {pearson_corr:.4f}\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
